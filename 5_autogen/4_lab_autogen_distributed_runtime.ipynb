{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504ae78e",
   "metadata": {},
   "source": [
    "# **AutoGen Core - Distributed Runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900f76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "ALL_IN_ONE_WORKER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0157bb",
   "metadata": {},
   "source": [
    "#### Start with our Message class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ab7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6b059",
   "metadata": {},
   "source": [
    "#### And now - a host for our distributed runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78136270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bf5b6",
   "metadata": {},
   "source": [
    "#### Let's reintroduce a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459351f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Useful for when you need to search the internet\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32955124",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6bc7f",
   "metadata": {},
   "source": [
    "#### And make some Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705e5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bba221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "\n",
    "if ALL_IN_ONE_WORKER:\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else:   # All agents in different runtimes and interacting within different runtimes\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19be15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await worker.send_message(Message(content=\"Go!\"), agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb1cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros of AutoGen:\n",
       "Here are some reasons in favor of choosing AutoGen for your AI Agent project:\n",
       "\n",
       "1. **Modularity and Scalability**: AutoGen's framework is designed to be modular and extensible, allowing for the creation of scalable and customizable systems that can grow with your project needs.\n",
       "\n",
       "2. **Ease of Use**: The integrated observability and debugging tools make it easier to monitor and control agent workflows, enhancing the development and maintenance process.\n",
       "\n",
       "3. **Multi-Agent Collaboration**: AutoGen excels in facilitating multi-agent systems, allowing for complex interactions and collaborations between agents, which can lead to more efficient and powerful AI solutions.\n",
       "\n",
       "4. **Customizable Agents**: The framework provides capabilities for creating customizable agents that can be easily tailored to specific requirements, ensuring flexibility in usage.\n",
       "\n",
       "5. **Efficiency in Tasks**: By leveraging AutoGenâ€™s tools, you can automate workflows and streamline processes, saving significant time and effort compared to traditional methods.\n",
       "\n",
       "6. **Integration Capabilities**: AutoGen can integrate with various LLMs, tools, and human inputs, making it versatile for diverse applications.\n",
       "\n",
       "These advantages make AutoGen a compelling choice for developing sophisticated AI agents in your project. \n",
       "\n",
       "TERMINATE\n",
       "\n",
       "## Cons of AutoGen:\n",
       "Here are some cons of using AutoGen in an AI Agent project:\n",
       "\n",
       "1. **Less Structured**: AutoGen may offer less structure than other frameworks, which could complicate codebase management and maintainability, especially for larger projects.\n",
       "\n",
       "2. **Accuracy Concerns**: There are challenges related to the accuracy of the models it employs, which could lead to unreliable outputs or behaviors in production settings.\n",
       "\n",
       "3. **Complex Deployment and Maintenance**: Managing the deployment and ongoing maintenance of AI features in real-world scenarios can be challenging, potentially requiring more resources and expertise.\n",
       "\n",
       "4. **Customization Complexity**: While it allows for customization, the need for deep reliance on frameworks can increase complexity, making it harder to implement tailored solutions.\n",
       "\n",
       "5. **Team Collaboration Issues**: Although it supports multi-agent collaboration, the coordination and communication between agents can sometimes lead to inefficiencies if not properly handled.\n",
       "\n",
       "Evaluating these drawbacks in the context of your specific project requirements is advisable before making a decision.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "\n",
       "## Decision:\n",
       "\n",
       "Based on the research provided by your team, I recommend choosing AutoGen for your AI Agent project.\n",
       "\n",
       "**Rationale**: The advantages of AutoGen, such as its modularity, scalability, ease of use, and multi-agent collaboration capabilities, significantly outweigh the concerns. While there are validity in the drawbacks regarding structure and accuracy, the benefits in efficiency and customization offer a strong case for leveraging AutoGen, especially if your project requires adaptability and collaboration among agents. With proper planning and resource allocation, the challenges can be managed effectively.\n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf0fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7462c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "await host.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
